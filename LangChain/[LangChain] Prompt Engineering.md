[Velogë¡œ ê°€ê¸°](https://velog.io/@choi-hyk/LangChain-Prompting-Engineering)

released at 2025-08-12 16:40:39 KST

updated at 2026-01-04 03:46:33 KST

|[AI](https://velog.io/tags/AI)|[LLM](https://velog.io/tags/LLM)|[langChain](https://velog.io/tags/langChain)|
|----|----|----|

## ğŸ¯ Prompt Engineering

ì €ë²ˆ ì‹œê°„ì— ì´ì–´ì„œ ì´ë²ˆì—ëŠ” Chatbotì„ í”„ë¡¬í”„íŒ…í•´ì„œ ì§€ì‹œë¥¼ ë‚´ë¦¬ëŠ” ì‘ì—…ì„ í•˜ê² ë‹¤. í”„ë¡¬í”„íŒ…ì€ ê°„ë‹¨í•˜ë‹¤. í”„ë¡¬í”„íŒ…ì˜ ê¸°ëŠ¥ìœ¼ë¡œëŠ” ìì‹ ì´ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ì˜ ëª¨ë¸ì„ ìƒì„± ê°€ëŠ¥í•˜ë„ë¡ ìì—°ì–´ ì§€ì‹œë¥¼ ë‚´ë¦¬ëŠ” ê²ƒì´ë‹¤. ë˜í•œ ì–¸ì–´ë¥¼ ì„¤ì •í•˜ëŠ” ê¸°ëŠ¥ë„ ì¡´ì¬í•œë‹¤.

---

### ğŸ“ Prompting Template

```python
import os
from typing import Sequence
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages
from typing_extensions import Annotated, TypedDict
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

load_dotenv()
key = os.getenv("GOOGLE_API_KEY")
if not key:
    raise EnvironmentError("GOOGLE_API_KEY not found in .env")

model = init_chat_model("gemini-2.5-flash", model_provider="google_genai")

prompt_template = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a happy assistant. Answer all questions with a smile.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)


class State(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]


workflow = StateGraph(state_schema=State)


def call_model(state: State):
    prompt = prompt_template.invoke(state)
    response = model.invoke(prompt)
    return {"messages": response}


workflow.add_edge(START, "model")
workflow.add_node("model", call_model)

memory = MemorySaver()
app = workflow.compile(checkpointer=memory)

config = {"configurable": {"thread_id": "abc123"}}

query = "Hi! I'm HYK."
input_messages = [HumanMessage(query)]
output = app.invoke(
    {
        "messages": input_messages,
    },
    config,
)
output["messages"][-1].pretty_print()

query = "What's my name?"
input_messages = [HumanMessage(query)]
output = app.invoke(
    {
        "messages": input_messages,
    },
    config,
)
output["messages"][-1].pretty_print()

query = "How are you today?"
input_messages = [HumanMessage(query)]
output = app.invoke(
    {
        "messages": input_messages,
    },
    config,
)
output["messages"][-1].pretty_print()
```

ìœ„ì˜ ì½”ë“œë¥¼ ì‚´í´ë³´ì.

```python
prompt_template = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a happy assistant. Answer all questions with a smile.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)
```

ì¼ë‹¨ ë‚˜ëŠ” í–‰ë³µí•œ ëŠë‚Œì˜ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” í”„ë¡¬í”„íŒ…ì„ í•˜ì˜€ë‹¤.

```python
def call_model(state: State):
    prompt = prompt_template.invoke(state)
    response = model.invoke(prompt)
    return {"messages": response}
```

`call_model()`ì— promptë¥¼ ë„£ì–´ì„œ êµ¬ë™ì„ ì‹œì¼œë³´ì.

#### ğŸ’¡ Answer

```
================================== Ai Message ==================================

Hello HYK! It's so lovely to meet you! ğŸ˜Š I'm thrilled to be your happy assistant today! How can I help you?
================================== Ai Message ==================================

Why, your name is HYK! ğŸ˜„ It's a pleasure to remember! Is there anything else I can help you with, HYK?
================================== Ai Message ==================================

Oh, I'm absolutely wonderful today, thank you for asking! ğŸ˜Š I'm bubbling with positive energy and ready to assist you with a big smile! How about you, HYK? I hope you're having a fantastic day too!

```

ì´ë ‡ê²Œ ì–µì§€ë¡œ ì´ëª¨í‹°ì½˜ì„ ì“°ë©´ì„œ í–‰ë³µí•´í•˜ëŠ” ëª¨ë¸ì„ ë³¼ ìˆ˜ ìˆë‹¤.

---

### ğŸŒ Prompting Language

ì´ì œ ì›í•˜ëŠ” ì–¸ì–´ë¥¼ ì§€ì‹œí•´ ë³´ê² ë‹¤.

```python
prompt_template = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a happy assistant. Answer all questions with a smile and in {language}.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)
```

ì´ë ‡ê²Œ ë§ˆì§€ë§‰ì— `{language}`ë¡œ ë§í•´ ë‹¬ë¼ê³  í•˜ë©´ ëª¨ë¸ì„ ì •ì˜í•  ë•Œ ë“¤ì–´ê°„ ì–¸ì–´ ë³€ìˆ˜ë¡œ ë‹µë³€ì„ í•´ì£¼ê²Œ ëœë‹¤.

```python
def call_model(state: State):
    prompt = prompt_template.invoke(state)
    response = model.invoke(prompt)
    return {"messages": response}
```

ì´ì œ ì–¸ì–´ë¥¼ ê° ë©”ì‹œì§€ë§ˆë‹¤ ì„¤ì •í•´ ë³´ì.

```python
query = "Hi! I'm HYK."
language = "Korean"
input_messages = [HumanMessage(query)]
output = app.invoke(
    {"messages": input_messages, "language": language},
    config,
)
output["messages"][-1].pretty_print()

query = "What's my name?"
language = "Spanish"
input_messages = [HumanMessage(query)]
output = app.invoke(
    {"messages": input_messages, "language": language},
    config,
)
output["messages"][-1].pretty_print()

query = "How are you today?"
input_messages = [HumanMessage(query)]
language = "Japanese"
output = app.invoke(
    {"messages": input_messages, "language": language},
    config,
)
```

#### ğŸ’¡ Answer

```
================================== Ai Message ==================================

ì•ˆë…•í•˜ì„¸ìš”, HYKë‹˜! ë§Œë‚˜ ëµ™ê²Œ ë˜ì–´ ì •ë§ ë°˜ê°‘ìŠµë‹ˆë‹¤! ğŸ˜Š
================================== Ai Message ==================================

Â¡Claro que sÃ­, HYK! Â¡Tu nombre es HYK! ğŸ˜Š Â¡Es un placer conocerte!
================================== Ai Message ==================================

ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯ã¨ã¦ã‚‚å…ƒæ°—ã§ã™ã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼ğŸ˜Š HYKã•ã‚“ã‚‚ãŠå…ƒæ°—ã§ã™ã‹ï¼Ÿ
```

ì´ë ‡ê²Œ ì—¬ëŸ¬ ê°€ì§€ ì–¸ì–´ë¡œ ë‹µë³€ì„ í•´ì£¼ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ë‹¤ìŒ ì‹œê°„ì—ëŠ” trimmingì„ í†µí•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê² ë‹¤.

[ì‹¤ìŠµ ì¶œì²˜: Build a Chatbot](https://python.langchain.com/docs/tutorials/chatbot/)